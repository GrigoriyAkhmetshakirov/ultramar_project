{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Крупнейший транспортно-логистический холдинг построил сортировочный терминал для минеральных удобрений. В рамках автоматиизации рабочих процессов, возникла необходимость распознавания номеров автомобильного транспорта, контейнеров и железнодорожных вагонов - все они учавствуют в логистической цепочке.\n",
    "В цепочке обычно учавствует один автомобиль, который перевозит два контейнера, куда засыпаются удобрения и один вагон из которого удобрения высыпаются.\n",
    "\n",
    "Общие цели автоматизации состояли в следующем:\n",
    "1) Отслеживание транспортных средств и контейнеров. Нужно точно следить за перемещением и идентификацией автомобилей, контейнеров и вагонов на протяжении всего пути;\n",
    "2) Интеграция данных в единую систему. Система должна обеспечить получение данных о всех элементах логистической цепочки в реальном времени для оптимизации работы;\n",
    "3) Управление загрузкой и разгрузкой. Чтобы точно отслеживать объемы и местоположение минеральных удобрений, важно иметь систему, которая будет связывать каждый контейнер с конкретным автомобилем и вагоном.\n",
    "\n",
    "Итого необходимо было разработать три системы:\n",
    "- Для распознавания номера контейнера;\n",
    "- Для распознавания номера автомобиля;\n",
    "- Для распознавания номера вагона."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На начальном этапе реализации проекта данных не было, и пилотная версия системы разрабатывалась и обучалась на общедоступных изображениях, только после постройки терминала и монтирования камер, были собраны релевантные изображения и дообучены модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт библиотек и модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from termcolor import cprint\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from paddleocr import PaddleOCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разработка системы распознавания номеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявим функцию для отображения изображений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(path, title=None, width=None, figsize=(10, 10)):\n",
    "    \"\"\"\n",
    "    Отображает изображение по заданному пути с возможностью добавления заголовка.\n",
    "\n",
    "    Аргументы:\n",
    "        path (str): Путь к изображению.\n",
    "        title (str, optional): Заголовок для изображения. По умолчанию - None.\n",
    "\n",
    "    Возвращает:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Загружаем изображение\n",
    "    try:\n",
    "        image = cv2.imread(path)\n",
    "    except:\n",
    "        image = path\n",
    "    # Проверяем, удалось ли загрузить изображение\n",
    "    if image is None:\n",
    "        print(f\"Ошибка: не удалось загрузить изображение по пути '{path}'\")\n",
    "        return\n",
    "    # Преобразуем цвет из BGR в RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Задаем размер\n",
    "    plt.figure(figsize=figsize)\n",
    "    # Отображаем изображение\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # Скрываем оси для чистого отображения\n",
    "    if title:\n",
    "        plt.title(title)  # Добавляем заголовок, если передан\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Распознавние номера контейнера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Номер контейнера состоит из 11 символов: 4 буквы и 7 цифр, причем последняя цифра является проверочнной - по ней можно проверить коректность номера. На данном объекте используются контейнеры с различными типами расположения номера, всего возможно три варианта:\n",
    "\n",
    "1-ый вариант, это номер, у которого цифры и буквы расположены в один вертикальный ряд:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('parsed_images', 'number_v')\n",
    "vert_numbers_list = os.listdir(path)\n",
    "show_image(os.path.join('parsed_images', 'number_v', vert_numbers_list[0]), '1-ый тип номера')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-ой вариант, это номер, у которого цифры и буквы расположены вертикально, но не в один ряд:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('parsed_images', 'number_v_dig')\n",
    "sep_vert_numbers_list = os.listdir(path)\n",
    "show_image(os.path.join(path, sep_vert_numbers_list[0]), '2-ой тип номера')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-ой вариант, это номер, у которого цифры и буквы расположены в один горизонтальный ряд:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('parsed_images', 'number_h')\n",
    "hor_numbers_list = os.listdir(path)\n",
    "show_image(os.path.join(path, hor_numbers_list[0]), '3-ий тип номера')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для распознавания текста были опробованы следующие библиотеки:\n",
    "- PaddleOCR;\n",
    "-  EasyOCR;\n",
    "-   Tesseract;\n",
    "-   apple_ocr. \n",
    "\n",
    "В итоге, в качестве модели для распознавания был выбран PaddleOCR. \n",
    "\n",
    "*Тут стоит уточнить, что на данном этапе не рассматривалась возможность дообучения моделей для детекции и распознавания текста, и PaddleOCR показал лучшие результаты на подготовленных изображениях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общий папйплайн обработки номера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обработки номера контейнера используется следующий пайплайн:\n",
    "1) Считывается изображение с камеры;\n",
    "2) Изображение подается на вход YOLO модели, которая обучена для детекции различных типов номеров.\n",
    "3) В зависимости от типа детектированного номера происходит дополнительная обработка номера;\n",
    "4) Производится подготовка изображения номера;\n",
    "5) Подготовленное изображение подается на вход OCR модели.\n",
    "\n",
    "Теперь по порядку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Считывание изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считывание, предобработка и вывод изображений производится с использование библиотеки **openCV**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Обучение модели и детектирование номеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После считывания изоюражения необходимо детектировать номер. Для детекции номеров используется нейросетевая модель на архитектуре YOLO. Была выбрана маленькая модель (s) 11 поколения.\n",
    "\n",
    "Модель обучалась с использованием пакета ultralytics. Меток детекции было 5: `['check_digit', 'number_h', 'number_v', 'number_v_dig', 'number_v_lett']`\n",
    "\n",
    "С помощью сервиса RoboFlow было размечено 1556 изображений, после аугментации было получено 4588 изображений, которые использовались для обучения.\n",
    "\n",
    "Обучение производилось в Google Colab с использованием GPU NVIDIA A100. \n",
    "\n",
    "Ниже представлен код обучения:\n",
    "\n",
    "```python\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "elif torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'CPU'\n",
    "    \n",
    "optimizer = 'NAdam'\n",
    "lr0 = 0.1\n",
    "lrf = 0.001\n",
    "epochs = 300\n",
    "batch_size = 64\n",
    "patience = 10\n",
    "resume=False\n",
    "\n",
    "model.train(data='/content/containers-15/data.yaml',\n",
    "            project=saving_log_dir,\n",
    "            resume=resume,\n",
    "            device=device,\n",
    "            lr0=lr0,\n",
    "            lrf=lrf,\n",
    "            cos_lr=True,\n",
    "            optimizer=optimizer,\n",
    "            epochs=epochs,\n",
    "            batch=batch_size,\n",
    "            patience=patience,\n",
    "            val=True,\n",
    "            visualize=True,\n",
    "            verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так выглядит один из тренировочных батчей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(os.path.join('images_for_project', 'train_batch0_numbers.jpg'), 'Тренировочный батч')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего понадобилось 226 эпох при размере батча в 64 изображения. Обучение составило около 3 часов.\n",
    "\n",
    "Ниже представлены метрики на лучшей эпохе:\n",
    "\n",
    "| epoch | train/box_loss | train/cls_loss | train/dfl_loss | metrics/precision(B) | metrics/recall(B) | metrics/mAP50(B) | metrics/mAP50-95(B) \n",
    "|-------|----------------|----------------|----------------|----------------------|--------------------|------------------|---------------------|\n",
    "| 223   | 0.69284       | 0.35574       | 0.84251       | 0.97653              | 0.96416           | 0.99117          | 0.86494             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(6, 6)\n",
    "show_image(os.path.join('images_for_project', 'P_curve_numbers.png'), 'Кривая Precision', figsize=figsize)\n",
    "show_image(os.path.join('images_for_project', 'R_curve_numbers.png'), 'Кривая Recall', figsize=figsize)\n",
    "show_image(os.path.join('images_for_project', 'PR_curve_numbers.png'), 'Кривая Precision-Recall', figsize=figsize)\n",
    "show_image(os.path.join('images_for_project', 'F1_curve_numbers.png'), 'Кривая F1', figsize=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее предсказание модели необходимо распарсить. Для этого объявим функцию, которая будет возвращать список пар `[тип номера, обрезанное_изображение]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_searching_model = YOLO(os.path.join('models_for_search', 'new_number_searching_model.pt'))\n",
    "\n",
    "def parse_predictions(image_path, show_cropped=False, show_predictions=False, model=None, conf=0.8, verbose=True):\n",
    "    \"\"\"\n",
    "    Выполняет предсказание на изображении, обрезает найденные объекты и, при необходимости, отображает их.\n",
    "\n",
    "    Аргументы:\n",
    "        image_path (str или ndarray): Путь к изображению или само изображение.\n",
    "        show_cropped (bool): Отображать ли каждое обрезанное изображение.\n",
    "        show_predictions (bool): Показывать ли полные предсказания модели.\n",
    "        model: Модель для предсказаний; если не передана, используется `number_searching_model`.\n",
    "        conf (float): Порог уверенности для предсказаний.\n",
    "        verbose (bool): Выводить ли сообщения.\n",
    "\n",
    "    Возвращает:\n",
    "        list: Список пар [класс, обрезанное_изображение] для найденных объектов или None, если объекты не обнаружены.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Загружаем изображение\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "    except:\n",
    "        image = image_path  # если передано само изображение\n",
    "    # Устанавливаем модель по умолчанию, если она не задана\n",
    "    if model is None:\n",
    "        model = number_searching_model\n",
    "    # Выполняем предсказание\n",
    "    cropped_images = []\n",
    "    predictions = model.predict(image, show=False, verbose=verbose, conf=conf)\n",
    "    # Показываем предсказания модели\n",
    "    if show_predictions:\n",
    "        predictions[0].show()\n",
    "    # Обрабатываем предсказания\n",
    "    classes = {0: 'check_digit', 1: 'number_h', 2: 'number_v', 3: 'number_v_dig', 4: 'number_v_lett'}\n",
    "    for prediction in predictions:\n",
    "        for box in prediction.boxes:\n",
    "            x1, y1, x2, y2, _, cls = box.numpy().data[0]\n",
    "            cropped_image = image[int(y1):int(y2), int(x1):int(x2)]\n",
    "            cropped_images.append([classes.get(cls), cropped_image])\n",
    "            # Отображаем обрезанное изображение, если нужно\n",
    "            if show_cropped:\n",
    "                show_image(cropped_image)\n",
    "    # Выводим результат\n",
    "    if len(cropped_images) == 0:\n",
    "        cprint('No cargo number detected', 'red', 'on_black') if verbose else None\n",
    "        return None\n",
    "    else:\n",
    "        cprint(f'Detected cargo number types is {[x[0] for x in cropped_images]}', 'green', 'on_black') if verbose else None\n",
    "        return cropped_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример использования функции для парсинга:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = os.path.join('parsed_images', 'number_v', vert_numbers_list[0])\n",
    "parsed_vertical = parse_predictions(image, show_cropped=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = os.path.join('parsed_images', 'number_h', hor_numbers_list[0])\n",
    "parsed_horizontal = parse_predictions(image, show_cropped=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = os.path.join('parsed_images', 'number_v_dig', sep_vert_numbers_list[0])\n",
    "parsed_vetical_sep = parse_predictions(image, show_cropped=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Обработка номера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того как мы получили вырезанные номера, их нужно преобразовать. Горизонтальные номера (3 тип) не требуют преобразования - их после подготовки можно сразу подавать на вход OCR модели.\n",
    "\n",
    "Номера у которых символы номера расположены в один вертикальный ряд (1 тип) преобразуем следующим образом:\n",
    "1) С помощью другой YOLO модели найдем все символы на обрезанном изображении;\n",
    "2) Вырежим эти символы, аналогично тому как мы это сделали с номерами;\n",
    "3) 'Соберем' эти символы в один горизонтальный ряд.\n",
    "\n",
    "Как и с случае с модели для детектирования номеров, мы будем использовать YOLO нейросетевую архитектуру. Изображения для обучения были получены с использованием модели для детектирования номеров - для 100 избражений были вырезанны номера и размечены символы, далее после аугментации получили 300 изображений и уже на них обучали нейросеть. Метка была одна: `symbol`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример тренировочного батча:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(os.path.join('images_for_project', 'train_batch0_symbols.jpg'), 'Тренировочный батч')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего понадобилось 78 эпох при размере батча в 32 изображения. Обучение составило около часа.\n",
    "\n",
    "Ниже представлены метрики на лучшей эпохе:\n",
    "\n",
    "| epoch | train/box_loss | train/cls_loss | train/dfl_loss | metrics/precision(B) | metrics/recall(B) | metrics/mAP50(B) | metrics/mAP50-95(B) \n",
    "|-------|----------------|----------------|----------------|----------------------|--------------------|------------------|---------------------|\n",
    "| 78   | 0.51208      | 0.30328      | 0.81092       | 0.99894        | 0.9987        | 0.995     | 0.87016           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(6, 6)\n",
    "show_image(os.path.join('images_for_project', 'P_curve_symbols.png'), 'Кривая Precision', figsize=figsize)\n",
    "show_image(os.path.join('images_for_project', 'R_curve_symbols.png'), 'Кривая Recall', figsize=figsize)\n",
    "show_image(os.path.join('images_for_project', 'PR_curve_symbols.png'), 'Кривая Precision-Recall', figsize=figsize)\n",
    "show_image(os.path.join('images_for_project', 'F1_curve_symbols.png'), 'Кривая F1', figsize=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После детекции всех символов на обрезнанном изображении, также вырезаем эти символы и 'склеиваем' их в один горизонтальный номер.\n",
    "\n",
    "Объявим функцию для преобразования номера к горизонтальному виду:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_model = YOLO(os.path.join('models_for_search', 'symbol_searching_model.pt'))\n",
    "\n",
    "def get_horizontal_number(image, h=640, w=320, show_horizontal=False, show_original=False, conf=0.7, show_predicted=False, verbose=False):\n",
    "    \"\"\"\n",
    "    Функция для поиска горизонтальных символов на изображении и отображения/обрезки этих символов.\n",
    "\n",
    "    Аргументы:\n",
    "        image (ndarray): Входное изображение для анализа.\n",
    "        h (int): Высота изображения, в которое будет преобразовано каждое обрезанное изображение.\n",
    "        w (int): Ширина изображения, в которое будет преобразовано каждое обрезанное изображение.\n",
    "        show_horizontal (bool): Показывать ли итоговое изображение с горизонтальными символами.\n",
    "        show_original (bool): Показывать ли оригинальное изображение.\n",
    "        conf (float): Порог уверенности для предсказаний модели.\n",
    "        show_predicted (bool): Показывать ли предсказания модели.\n",
    "        verbose (bool): Выводить ли дополнительные сообщения в процессе выполнения.\n",
    "\n",
    "    Возвращает:\n",
    "        ndarray: Итоговое изображение с распознанными горизонтальными символами.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Если нужно, показываем оригинальное изображение\n",
    "    if show_original:\n",
    "        cprint('Original image is:', 'green', 'on_black')\n",
    "        show_image(image)\n",
    "    # Получаем размеры изображения (высота и ширина)\n",
    "    height, width, _ = image.shape\n",
    "    # Если изображение вертикальное (высота больше ширины)\n",
    "    if height > width:\n",
    "        # Если включен параметр verbose, выводим сообщение о вертикальном изображении\n",
    "        cprint('Vertical image is detected', 'green', 'on_black') if verbose else None\n",
    "        # Прогнозируем символы на изображении с использованием модели\n",
    "        predictions = horizontal_model.predict(image, save_crop=False, conf=conf, verbose=verbose)\n",
    "        # Извлекаем найденные боксы (границы символов)\n",
    "        boxes = predictions[0].boxes.numpy().data\n",
    "        # Проверяем, что количество обнаруженных символов соответствует одному из допустимых вариантов\n",
    "        if len(boxes) not in [11, 7, 4]:\n",
    "            # Если количество символов неверное, выводим сообщение и возвращаем None\n",
    "            cprint('Not enough symbols detected', 'red', 'on_black') if verbose else None\n",
    "            return None\n",
    "        # Создаем пустое изображение для дальнейшего объединения обрезанных символов\n",
    "        res = np.zeros((h, 1, 3), np.uint8)\n",
    "        # Сортируем боксы по вертикальной координате и обрезаем изображения символов\n",
    "        for box in sorted(boxes, key=lambda x: x[1]):\n",
    "            # Извлекаем координаты бокса\n",
    "            x1, y1, x2, y2, conf, _ = box\n",
    "            # Обрезаем изображение по этим координатам\n",
    "            imgCrop = image[int(y1):int(y2), int(x1):int(x2)]\n",
    "            # Изменяем размер обрезанного изображения и добавляем его в итоговое изображение\n",
    "            res = cv2.hconcat([res, cv2.resize(imgCrop, (w, h))])\n",
    "        # Если нужно, показываем предсказания модели\n",
    "        if show_predicted:\n",
    "            cprint('Predicted symbols is:', 'green', 'on_black')\n",
    "            predictions[0].show()\n",
    "    # Если изображение горизонтальное (ширина больше или равна высоте)\n",
    "    else:\n",
    "        # Если включен параметр verbose, выводим сообщение о горизонтальном изображении\n",
    "        cprint('Horizontal image is detected', 'green', 'on_black') if verbose else None\n",
    "        # В этом случае, просто возвращаем оригинальное изображение\n",
    "        res = image\n",
    "    # Если нужно, показываем итоговое изображение с горизонтальными символами\n",
    "    if show_horizontal:\n",
    "        cprint('Horizontal number is:', 'green', 'on_black')\n",
    "        show_image(res)\n",
    "    # Возвращаем итоговое изображение\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_number = get_horizontal_number(parsed_vertical[1][1], verbose=True, show_horizontal=True, show_original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_number = get_horizontal_number(parsed_horizontal[0][1], verbose=True, show_horizontal=True, show_original=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Номера, у которого цифры и буквы расположены вертикально, но не в один ряд (2 тип), обрабатываются аналогично, но добалвяется еще один шаг - полученные изображения с выхода первой модели для детекции с метками 'number_v_dig' и 'number_v_lett' 'склеиваем' сначала в один вертикальный номер, а затем детектируем на этом изображении символы и собираем в горизонатльный номер, как это было с номером 1-го типа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(image, size=(640, 160), resize=False, gray=False, show=False, thresh=0, blure=15):\n",
    "    \"\"\"\n",
    "    Подготавливает изображение для дальнейшей обработки: изменяет размер, переводит в нужный цветовой формат,\n",
    "    применяет пороговую обработку и блюринг, если необходимо.\n",
    "\n",
    "    Аргументы:\n",
    "        image (ndarray): Входное изображение.\n",
    "        size (tuple): Размер изображения для изменения.\n",
    "        resize (bool): Флаг изменения размера.\n",
    "        gray (bool): Флаг перевода изображения в оттенки серого.\n",
    "        show (bool): Флаг отображения изображения после обработки.\n",
    "        thresh (int): Порог для преобразования в бинарное изображение.\n",
    "        blure (int): Уровень блюра для размытия.\n",
    "\n",
    "    Возвращает:\n",
    "        image (ndarray): Обработанное изображение.\n",
    "    \"\"\"\n",
    "    # Меняем размер\n",
    "    if resize:\n",
    "        image = cv2.resize(image, size)\n",
    "    \n",
    "    # Преобразуем изображение в оттенки серого\n",
    "    if gray or thresh:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Медианный блюр и пороговая обработка\n",
    "    if thresh:\n",
    "        image = cv2.medianBlur(image, blure)\n",
    "        _, image = cv2.threshold(image, thresh, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Отображение\n",
    "    if show:\n",
    "        cprint('Prepared image is:', 'green', 'on_black')\n",
    "        show_image(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_model_path = os.path.join('models_for_search', 'det', 'en', 'en_PP-OCRv3_det_infer')\n",
    "rec_model_path = os.path.join('models_for_search', 'rec', 'en', 'ch_ppocr_server_v2.0_rec_train')\n",
    "cls_model_path = os.path.join('models_for_search', 'rec', 'en', 'ch_ppocr_mobile_v2.0_cls_infer')\n",
    "\n",
    "ocr_reader = PaddleOCR(lang='en',\n",
    "                       show_log=False,\n",
    "                       use_angle_cls=True,\n",
    "                       det_model_dir=det_model_path,\n",
    "                       rec_model_dir=rec_model_path,\n",
    "                       cls_model_dir=cls_model_path,\n",
    ")\n",
    "\n",
    "def get_text(file):\n",
    "    \"\"\"\n",
    "    Распознает и возращает текст.\n",
    "\n",
    "    Аргументы:\n",
    "        file (ndarray): Входное изображение.\n",
    "\n",
    "    Возвращает:\n",
    "        text (str): Распознанный текст.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return ocr_reader.ocr(file)\n",
    "    except:\n",
    "        cprint('No text on the image', 'red', 'onblack')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_number(number, verbose=False):\n",
    "    \"\"\"\n",
    "    Проверяет корректность контрольной цифры в номере на основе алгоритма вычисления контрольной суммы.\n",
    "  \n",
    "    Аргументы:\n",
    "        number (str): Номер, в котором проверяется контрольная цифра.\n",
    "        verbose (bool): Флаг для отображения информации о вычисленной контрольной цифре (по умолчанию False).\n",
    "\n",
    "    Возвращает:\n",
    "        bool: Возвращает True, если контрольная цифра правильная, и False, если нет.\n",
    "    \"\"\"\n",
    "\n",
    "    alphabet = {**{'U': 32, 'M': 24, 'T': 31, 'L': 23}, **{str(x): x for x in range(10)}}\n",
    "    res = 0\n",
    "    # Проходим по всем символам в номере, кроме последнего, и рассчитываем контрольную сумму\n",
    "    for i, sym in enumerate(number[:-1]):\n",
    "        # Для каждого символа в номере прибавляем его значение с учетом его позиции\n",
    "        res = res + 2**i * alphabet.get(sym, 0)\n",
    "    res = res % 11 % 10\n",
    "    cprint(f'Calculated check digit is: {res}', 'blue') if verbose else None\n",
    "    return str(res) == number[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cargo_number(\n",
    "    file,\n",
    "    show_horizontal=False,\n",
    "    show_original=False,\n",
    "    show_prepared=False,\n",
    "    print_pred_text=False,\n",
    "    show_predictions=False,\n",
    "    show_cropped=False,\n",
    "    thresh_horizontal_number=0,\n",
    "    thresh_vertical_number=1,\n",
    "    thresh_check_digit=1,\n",
    "    blure_horizontal_number=1,\n",
    "    blure_vertical_number=7,\n",
    "    blure_check_digit=7,\n",
    "    size_number=(640, 160),\n",
    "    size_check_digit=(200, 200),\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Распознаёт номер контейнера на изображении и возвращает его в формате ISO 6346.\n",
    "\n",
    "    Аргументы:\n",
    "        file (str): Путь к входному изображению.\n",
    "        show_horizontal (bool): Флаг отображения горизонтально обработанных изображений.\n",
    "        show_original (bool): Флаг отображения исходного изображения.\n",
    "        show_prepared (bool): Флаг отображения подготовленных изображений.\n",
    "        print_pred_text (bool): Флаг отображения текста, полученного с OCR.\n",
    "        show_predictions (bool): Флаг отображения предсказаний модели.\n",
    "        show_cropped (bool): Флаг отображения обрезанных изображений.\n",
    "        thresh_horizontal_number (int): Пороговая обработка для горизонтальных номеров.\n",
    "        thresh_vertical_number (int): Пороговая обработка для вертикальных номеров.\n",
    "        thresh_check_digit (int): Пороговая обработка для контрольной цифры.\n",
    "        blure_horizontal_number (int): Уровень блюра для горизонтальных номеров.\n",
    "        blure_vertical_number (int): Уровень блюра для вертикальных номеров.\n",
    "        blure_check_digit (int): Уровень блюра для контрольной цифры.\n",
    "        size_number (tuple): Размер изображения номера контейнера.\n",
    "        size_check_digit (tuple): Размер изображения контрольной цифры.\n",
    "        verbose (bool): Флаг подробного вывода сообщений.\n",
    "\n",
    "    Возвращает:\n",
    "        str: Распознанный номер контейнера, если он соответствует формату ISO 6346. Иначе None.\n",
    "    \"\"\"\n",
    "    # Парсинг предсказаний модели и получение обрезанных изображений\n",
    "    cropped_images = parse_predictions(\n",
    "        file, show_cropped=show_cropped, show_predictions=show_predictions, verbose=verbose\n",
    "    )\n",
    "    if cropped_images is None:\n",
    "        if verbose:\n",
    "            cprint('No images to work', 'red', 'on_black')\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        number_types = [x[0] for x in cropped_images]\n",
    "\n",
    "        for image in cropped_images:\n",
    "            # Обработка вертикальных номеров контейнеров\n",
    "            if image[0] == 'number_v':\n",
    "                number = get_horizontal_number(\n",
    "                    image[1],\n",
    "                    show_horizontal=show_horizontal,\n",
    "                    show_original=show_original,\n",
    "                    verbose=verbose,\n",
    "                )\n",
    "                prepared_image = prepare_image(\n",
    "                    number,\n",
    "                    thresh=thresh_vertical_number,\n",
    "                    blure=blure_vertical_number,\n",
    "                    show=show_prepared,\n",
    "                    resize=True,\n",
    "                    size=size_number,\n",
    "                )\n",
    "                text = get_text(prepared_image)[0][0][1][0]\n",
    "                if print_pred_text:\n",
    "                    cprint(f'Text after OCR is {text}', 'blue')\n",
    "\n",
    "            # Обработка горизонтальных номеров контейнеров\n",
    "            if image[0] == 'number_h':\n",
    "                number = get_horizontal_number(\n",
    "                    image[1],\n",
    "                    show_horizontal=show_horizontal,\n",
    "                    show_original=show_original,\n",
    "                    verbose=verbose,\n",
    "                )\n",
    "                prepared_image = prepare_image(\n",
    "                    number,\n",
    "                    thresh=thresh_horizontal_number,\n",
    "                    blure=blure_horizontal_number,\n",
    "                    show=show_prepared,\n",
    "                    resize=True,\n",
    "                    size=size_number,\n",
    "                )\n",
    "                texts = get_text(prepared_image)\n",
    "                if print_pred_text:\n",
    "                    cprint(f'Text after OCR is {texts}', 'blue')\n",
    "\n",
    "                # Обработка текстов и формирование итогового текста\n",
    "                text_list = []\n",
    "                for el in texts[0]:\n",
    "                    if len(el[1][0]) in [4, 6]:\n",
    "                        text_list.append(el[1][0])\n",
    "\n",
    "                text = ''.join(sorted(text_list, reverse=True))\n",
    "                if print_pred_text:\n",
    "                    cprint(f'Text after preparing is {text}', 'blue')\n",
    "\n",
    "            # Обработка контрольной цифры\n",
    "            if image[0] == 'check_digit' and 'number_h' in number_types:\n",
    "                prepared_image = prepare_image(\n",
    "                    image[1],\n",
    "                    thresh=thresh_check_digit,\n",
    "                    blure=blure_check_digit,\n",
    "                    show=show_prepared,\n",
    "                    resize=True,\n",
    "                    size=size_check_digit,\n",
    "                )\n",
    "                try:\n",
    "                    check_digit_text = get_text(prepared_image)[0][0][1][0]\n",
    "                    for el in check_digit_text:\n",
    "                        if el.isdigit():\n",
    "                            check_digit = el\n",
    "                            break\n",
    "                    if verbose:\n",
    "                        cprint(f'Detected check digit is: {check_digit}', 'blue')\n",
    "                except Exception:\n",
    "                    check_digit = None\n",
    "                    if verbose:\n",
    "                        cprint('No check digit detected', 'red', 'on_black')\n",
    "\n",
    "            # Обработка вертикальных частей номера (буквы и цифры)\n",
    "            if image[0] == 'number_v_dig':\n",
    "                number_v_dig = cv2.resize(image[1], (90, 600))\n",
    "\n",
    "            if image[0] == 'number_v_lett':\n",
    "                number_v_lett = cv2.resize(image[1], (90, 300))\n",
    "\n",
    "        # Формирование полного вертикального номера\n",
    "        if 'number_v_lett' in number_types and 'number_v_dig' in number_types:\n",
    "            collected_number = cv2.vconcat([number_v_lett, number_v_dig])\n",
    "            number = get_horizontal_number(\n",
    "                collected_number,\n",
    "                show_horizontal=show_horizontal,\n",
    "                show_original=show_original,\n",
    "                verbose=verbose,\n",
    "            )\n",
    "            prepared_image = prepare_image(\n",
    "                number,\n",
    "                thresh=1,\n",
    "                blure=7,\n",
    "                show=show_prepared,\n",
    "                resize=True,\n",
    "                size=(640, 160),\n",
    "            )\n",
    "            text = get_text(prepared_image)[0][0][1][0]\n",
    "\n",
    "        # Постобработка текста для исправления формата\n",
    "        if text[2] == 'T' and len(text) == 11:\n",
    "            text = 'UMTU' + text[4:10] + text[-1]\n",
    "\n",
    "        if text[2] == 'L' and len(text) == 11:\n",
    "            text = 'UMLU' + text[4:10] + text[-1]\n",
    "\n",
    "        if text[2] == 'L' and len(text) != 11 and check_digit:\n",
    "            text = 'UMLU' + text[4:10] + check_digit\n",
    "\n",
    "    except Exception as e:\n",
    "        # Обработка ошибок\n",
    "        cprint(e, 'red', 'on_black')\n",
    "        return None\n",
    "\n",
    "    if verbose:\n",
    "        cprint(f'Detected text is {text}', 'blue')\n",
    "\n",
    "    # Проверка корректности текста согласно стандарту ISO 6346\n",
    "    if len(text) == 11 and text[0:4].isalpha() and text[4:].isdigit() and check_number(text, verbose=verbose):\n",
    "        return text\n",
    "\n",
    "    if verbose:\n",
    "        cprint(f'Prepared text {text} is wrong', 'red', 'on_black')\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = os.path.join('parsed_images', 'number_v', vert_numbers_list[0])\n",
    "show_image(image)\n",
    "get_cargo_number(image, show_original=True, show_cropped=False, show_prepared=True, show_horizontal=True, show_predictions=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
